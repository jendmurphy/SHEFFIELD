theme(axis.text.x=element_text(angle=45, hjust=1))
df_trump %>%
filter(term=="fake") %>%
group_by(document) %>%
ggplot(aes(x = document, y = count)) +
geom_bar(stat = "identity") +
ggtitle("Occurrences of 'Obama' in Trump speeches") +
labs(x="", y="Word frequency") +
theme(axis.text.x=element_text(angle=45, hjust=1))
df_trump %>%
filter(term=="america") %>%
group_by(document) %>%
ggplot(aes(x = document, y = count)) +
geom_bar(stat = "identity") +
ggtitle("Occurrences of 'Obama' in Trump speeches") +
labs(x="", y="Word frequency") +
theme(axis.text.x=element_text(angle=45, hjust=1))
df_trump %>%
filter(term=="god") %>%
group_by(document) %>%
ggplot(aes(x = document, y = count)) +
geom_bar(stat = "identity") +
ggtitle("Occurrences of 'Obama' in Trump speeches") +
labs(x="", y="Word frequency") +
theme(axis.text.x=element_text(angle=45, hjust=1))
df_trump %>%
filter(term=="obama") %>%
group_by(document) %>%
ggplot(aes(x = document, y = count)) +
geom_bar(stat = "identity") +
ggtitle("Occurrences of 'Obama' in Trump speeches") +
labs(x="", y="Word frequency") +
theme(axis.text.x=element_text(angle=45, hjust=1))
findAssocs(trumpDTM, "clinton", corlimit = 0.6)
require(tm)
findAssocs(trumpDTM, "clinton", corlimit = 0.6)
findAssocs(trumpDTM, "clinton", corlimit = 0.9)
install.packages("proxy")
library(proxy)
sparsetrumpDTM <- removeSparseTerms(trumpDTM, sparse=0.95)
mat <- as.matrix(sparsetrumpDTM)
docsdissim <- dist(scale(mat))
h <- hclust(docsdissim, method = "ward.D")
plot(h, cex=0.8, hang=0.1)
h2<- hclust(docsdissim, method = "complete")
plot(h2, cex=0.8, hang=0.1)
h <- hclust(docsdissim, method = "ward.D")
plot(h, cex=0.8, hang=0.1)
# demonstrate clustering using k-means
install.packages("fpc")
install.packages("cluster")
library(fpc)
library(cluster)
kfit <- kmeans(docsdissim, 2)
clusplot(as.matrix(docsdissim), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- kmeans(docsdissim, 3)
clusplot(as.matrix(docsdissim), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- kmeans(docsdissim, 2)
clusplot(as.matrix(docsdissim), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(tidytext)
library(dplyr)
library(janeaustenr)
library(stringr)
View(austen_books())
austen_books() %>%
group_by(book) %>%
summarise(total_lines = n())
summary<-austen_books() %>%
group_by(book) %>%
summarise(total_lines = n())
summary
View(summary)
austenTidyBooks <- austen_books() %>%
unnest_tokens(word, text)
summary<-austen_books() %>%
group_by(book) %>%
summarise(total_lines = n()) %>% #total_lines is the name of the variable created
ungroup
View(summary)
summary<-austen_books() %>%
group_by(book) %>%
summarise(total_lines = n()) %>% #total_lines is the name of the variable created
ungroup()
View(summary)
austenTidyBooks
austenTidyBooks <- austen_books() %>%
group_by(book) %>%
mutate(linenumber=row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
austenTidyBooks
austenTidyBooks <- austen_books() %>%
group_by(book) %>%
mutate(linenumber=row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
austenTidyBooks
austenTidyBooks <- austen_books() %>%
group_by(book) %>%
mutate(linenumber=row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
austenTidyBooks
austenTidyBooks <- austen_books() %>%
unnest_tokens(word, text)
austenTidyBooks
austenTidyBooks <- austen_books() %>%
group_by(book) %>%
mutate(linenumber=row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
austenTidyBooks
txt <- readtext("http://ir.shef.ac.uk/cloughie/download/inaugral.txt") # plaintext
txt_df <- txt %>%
unnest_tokens(word, text)
View(txt_df)
trumpCorpus <- VCorpus(DirSource("./texts", encoding="UTF-8"))
trumpTxt <- tidy(trumpCorpus)
trumpTxt
trumpTxt$id
trumpTxt$text
View(trumpTxt)
tidyTrumpTxt <- trumpTxt %>%
select(text, id) %>%
group_by(id) %>%
unnest_tokens(word, text) %>%
ungroup() # you can experiment with not including this when you compute count()
tidyTrumpTxt
trumpDTM <- DocumentTermMatrix(trumpCorpus)
tidyTrumpTDM <- tidy(trumpDTM)
tidyTrumpTDM
austenTidyBooks %>%
count(word, sort=TRUE)
austenTidyBooks %>%
group_by(book) %>%
count(word, sort=TRUE)
austenTidyBooks %>%
group_by(book) %>%
mutate(unique = n_distinct(word)) %>%
count(book, unique)
data(stop_words)
austenTidyBooks<-austenTidyBooks %>%
anti_join(stop_words)
austenTidyBooks %>%
count(word, sort=TRUE)
View(tidyTrumpTDM)
View(tidyTrumpTxt)
View(trumpTxt)
View(tidyTrumpTDM)
inspect(trumpDTM)
df_trumpDTM <- data.frame(trumpDTM)
tbl_df(trumpDTM)
View(df_trump)
DF <- data.frame(as.matrix(trumpDTM), stringsAsFactors=FALSE)
View(DF)
austenTidyBooks<-austenTidyBooks %>%
anti_join(stop_words)
austenTidyBooks %>%
count(word, sort=TRUE)
austenTidyBooks %>%
count(word, sort=TRUE) %>%
filter(n>500) %>%
mutate(word=reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
wordsToFilterOut <- c("miss", "time")
austenTidyBooks %>%
filter(!word %in% wordsToFilterOut) %>%
count(word, sort=TRUE)
austenTidyBooks %>%
filter(book=="Emma") %>%
count(word, sort = TRUE)
austenTidyBooks %>%
count(book, word, sort=TRUE) %>%
austenTidyBooks %>%
group_by(book) %>%
count(word, sort=TRUE)
austenTidyBooks %>%
count(book, word, sort=TRUE) %>%
austenTidyBooks %>%
group_by(book) %>%
count(word, sort=TRUE)
austenTidyBooks %>%
group_by(book) %>%
count(word, sort=TRUE)
tidyTrumpTxt <- tidyTrumpTxt %>%
anti_join(stop_words)
tidyTrumpTxt %>%
count(word, sort=TRUE)
tidyTrumpTxt %>%
count(id, word, sort=TRUE)
o
austenTFIDF<-austenTidyBooks %>%
count(book, word, sort=TRUE) %>%
bind_tf_idf(word, book, n) %>%
arrange(desc(tf_idf))
austenTFIDF
austenTFIDF %>%
group_by(book) %>%
top_n(12, tf_idf) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ book, scales = "free") +
ylab("tf-idf") +
coord_flip()
austenTFIDF %>%
group_by(book) %>%
top_n(12, tf_idf) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
#  facet_wrap(~ book, scales = "free") +
ylab("tf-idf") +
coord_flip()
austenTFIDF %>%
group_by(book) %>%
top_n(12, tf_idf) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ book, scales = "free") +
ylab("tf-idf") +
coord_flip()
trumpTFIDF <- tidyTrumpTxt %>%
count(id, word, sort=TRUE) %>%
bind_tf_idf(word, id, n) %>%
arrange(desc(tf_idf))
trumpTFIDF
trumpTFIDF %>%
group_by(id) %>%
top_n(12, tf_idf) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = id)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ id, scales = "free") +
ylab("tf-idf") +
coord_flip()
austen_bigrams <- austen_books() %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
austen_bigrams %>%
count(bigram, sort = TRUE)
austen_bigrams <- austen_books() %>%
unnest_tokens(bigram, text, token = "ngrams", n = 3)
austen_bigrams %>%
count(bigram, sort = TRUE)
austen_bigrams <- austen_books() %>%
unnest_tokens(bigram, text, token = "ngrams", n = 5)
austen_bigrams %>%
count(bigram, sort = TRUE)
austen_bigrams <- austen_books() %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
austen_bigrams %>%
count(bigram, sort = TRUE)
bigrams_separated <- austen_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams_filtered
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigrams_united
bigram_counts <- bigrams_united %>%
count(bigram, sort=TRUE)
bigram_counts
# KJV Bible example
install.packages("gutenbergr")
library(gutenbergr)
library(stringr)
library(dplyr)
library(tidyr)
library(igraph)
library(ggraph)
library(tidyverse)
library(tidytext)
count_bigrams <- function(dataset) {
dataset %>%
unnest_tokens(bigram, text, token="ngrams", n=2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word) %>%
count(word1, word2, sort=TRUE)
}
visualize_bigrams <- function(bigrams) {
set.seed(2016)
a <- grid::arrow(type="closed", length=unit(.08, "inches"))
bigrams %>%
graph_from_data_frame() %>%
ggraph(layout="fr") +
geom_edge_link(aes(edge_alpha=n), show.legend=FALSE, arrow=a) +
geom_node_point(color="red", size=2) +
geom_node_text(aes(label=name), repel=TRUE) +
theme_void() +
theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
}
kjv <- gutenberg_download(10)
kjv <- gutenberg_download(10)
kjv
kjv_bigrams <- kjv %>%
count_bigrams()
kjv_bigrams
kjv_bigrams %>%
filter(n>20,
!str_detect(word1, "\\d"),
!str_detect(word2, "\\d")) %>%
visualize_bigrams()
kjv_bigrams %>%
filter(n>20,
!str_detect(word1, "\\d"),
!str_detect(word2, "\\d")) %>%
visualize_bigrams()
sentiments
get_sentiments("bing")
get_sentiments("nrc")
get_sentiments("bing")
get_sentiments("nrc") %>%
group_by(sentiment) %>%
summarise(count = n())
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
select(word, sentiment)
nrc
austenTidyBooks %>%
filter(book=="Emma") %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n_distinct(word))
nrcAnger <- get_sentiments("nrc") %>%
filter(sentiment=="anger")
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(nrcAnger) %>%
count(word, sort = TRUE)
library(reshape2)
austenTidyBooks %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
library(wordcloud)
austenTidyBooks %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
austenTidyBooks %>%
group_by(book) %>%
mutate(unique = n_distinct(word)) %>%
count(book, unique)
m
get_sentiments("nrc") %>%
group_by(sentiment) %>%
summarise(count = n())
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
select(word, sentiment)
nrc
austenTidyBooks %>%
filter(book=="Emma") %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n())
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n_distinct(word))
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("bing")) %>%
summarise(count = n_distinct(word))
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("Afinn")) %>%
summarise(count = n_distinct(word))
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("afinn")) %>%
summarise(count = n_distinct(word))
austenTidyBooks %>%
filter(book=="Emma") %>%
distinct(word) %>%
inner_join(get_sentiments("nrc")) %>%
summarise(count = n_distinct(word))
nrcAnger <- get_sentiments("nrc") %>%
filter(sentiment=="anger")
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(nrcAnger) %>%
count(word, sort = TRUE)
austenTidyBooks %>%
filter(book=="Emma") %>%
inner_join(nrcAnger) %>%
count(word, sort = TRUE)
library(reshape2)
library(wordcloud)
austenTidyBooks %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
tidyTrumpTxt %>%
inner_join(nrc, by = "word") %>%
count(id, sentiment, word) %>%
ungroup() %>%
group_by(sentiment) %>%
summarize(words = sum(n))
tidyTrumpTxt %>%
inner_join(get_sentiments("bing"))
tidyTrumpTxt %>%
inner_join(get_sentiments("bing"), by = c(term = "word")) %>%
count(term, sentiment, sort = TRUE) %>%
acast(term ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
View(tidyTrumpTxt)
tidyTrumpTxt %>%
inner_join(get_sentiments("bing"), by = word)) %>%
count(term, sentiment, sort = TRUE) %>%
acast(term ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
tidyTrumpTxt %>%
inner_join(get_sentiments("bing"), by = word)) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
tidyTrumpTxt %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 100)
install.packages("syuzhet")
library(syuzhet)
get_sentiment(trumpTxt$text) %>% as.numeric()
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col=heat.colors(8),
main = "Emotions in Trump's tweets", xlab="Percentage"
)
nrc_data <- get_nrc_sentiment(trumpTxt$text)
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col=heat.colors(8),
main = "Emotions in Trump's tweets", xlab="Percentage"
)
expectations <- gutenberg_download(1400)
expectations_bigrams <- expectations %>%
count_bigrams()
expectations_bigrams %>%
filter(n>3,
!str_detect(word1, "\\d"),
!str_detect(word2, "\\d")) %>%
visualize_bigrams()
library(igraph)
install.packages("igraph")
install.packages("ggraph")
library(igraph)
library(ggraph)
expectations_bigrams <- expectations %>%
count_bigrams()
expectations_bigrams %>%
filter(n>3,
!str_detect(word1, "\\d"),
!str_detect(word2, "\\d")) %>%
visualize_bigrams()
